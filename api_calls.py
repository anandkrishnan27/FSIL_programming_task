"""
api_calls.py contains functions that take the item 7a. data cleaned by parse.py 
and call the GPT-3.5-turbo API to generate insight on this text
"""
from openai import OpenAI
from dotenv import load_dotenv

"""
Function pick_years(): returns a list of evenly-spaced files from the 29 10-K 
documents downloaded since we cannot pass all 29 to the API for sake of tokens
@ param filings: list of all 10-K file names
@ param num_to_pick: int representing how many files we want to choose evenly spaced
@ return: final_list: list of selected evenly-spaced filenames to be passed to API
"""
def pick_years(filings, num_to_pick):
    final_list = []
    if len(filings) <= 0: return final_list

    step_size = len(filings) / (num_to_pick - 1)

    # loop selects certain filenames from the filings list to be considered
    for i in range(num_to_pick - 1):
        index = int(i * step_size)
        final_list.append(filings[index])
    
    final_list.append(filings[len(filings) - 1]) # the last file (most recent) will always be considered
    return final_list

"""
Function generate_prompt: aggregates all filings into a single string prompt for the API to analyze
@ param filings: list of filenames to be included in prompt
@ return prompt: string with each 10-K section for the API to parse
"""
def generate_prompt(filings):
    prompt = ""
    filepath = "/Users/anandkrishnan/Desktop/FSIL project/sec-edgar-filings/financial_statements/"

    # accesses each file from the directory and adds its text to the string
    for filing in filings:
        current_filepath = filepath + filing

        with open(current_filepath) as f:
            contents = f.read()
            prompt += contents
            prompt += "\n\n"
    
    return prompt

"""
Function run_api: calls OpenAI GPT-3.5-turbo API to analyze the 10-K data aggregated by above functions
and answers certain pre-coded questions relating to market risk for the entered firm.
@ param company: string name of ticker to be analyzed
@ param filing_data: string generated by generate_prompt() to be passed to API
"""
def run_api(company, filing_data):
    results = []
    load_dotenv()
    client = OpenAI(api_key="INSERT API KEY HERE")

    # this string assigns the API what role it should be taking on and passes in its filing data
    primer = f"""You are a very confident, knowledgeable, and specific market analyst who can analyze market risk factors
    affecting a company. Parse the below excerpts from {company}'s 10-K item 7a and answer the following questions. Item 7a over 
    time for {company} is below. Make sure your answers use {company}'s name and don't include bulleted/numbered lists.""" + '\n\n' + filing_data

    # questions I chose to ask the API to give insight on market risk
    questions = ["What are some possible macroeconomic factors that pose risk to this firm?",
                "Give a future outlook for this firm's risk profile", 
                "How risky are this firm's investments historically?", 
                "How should this company improve in order to lessen its risk profile?", 
                "Give me some matplotlib code that generates one specific graph based on this data."]
    
    # N.B. I had initially planned to have the API generate matplotlib code (as seen above) for me to display as a graph,
    # but I was unable to properly implement this functionality. I am leaving the question (and the code that the API 
    # generates) as part of my code, but it has no real use. 

    # looping through each question and capturing the API response as a string in the "results" list
    for question in questions:
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                # sending the primer message with each question isn't ideal, but it was the only way I could get it to work
                {"role": "system", "content": primer},
                {"role": "user", "content": question}
            ]
        )   
        results.append(completion.choices[0].message)

    return results
